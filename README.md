# GestureFlow: Controle do Spotify por Gestos com YOLOv8

<div align="center">
  <img src="https://github.com/R1chardJr/YOLOV8-Gesture-Based-Media-Control/blob/main/gif_example.gif" width="500">
</div>
<p align="center">
  GIF de exemplo de funcionamento do projeto
</p>

## üìñ Sobre o Projeto

O **GestureFlow** √© uma aplica√ß√£o de Vis√£o Computacional desenvolvida em Python que permite ao usu√°rio controlar o player de m√∫sica do Spotify atrav√©s de gestos com a m√£o, capturados em tempo real por uma webcam. O projeto utiliza o modelo de detec√ß√£o de objetos **YOLOv8** para reconhecer os gestos e se comunica diretamente com a **API do Spotify** para executar os comandos, criando uma experi√™ncia de Intera√ß√£o Humano-Computador fluida e intuitiva.

Este projeto foi desenvolvido como um trabalho final de Redes Neurais, explorando o ciclo de vida completo de um projeto de Machine Learning, desde a coleta e anota√ß√£o de dados at√© o treinamento do modelo e a cria√ß√£o de uma aplica√ß√£o funcional. 

## ‚ú® Funcionalidades

* **Detec√ß√£o em Tempo Real:** Reconhece gestos a partir do feed de uma webcam com alta velocidade e precis√£o.
* **Controle de Reprodu√ß√£o:**
    * **Play/Pause (Punho fechado ‚úä):** Inicia ou pausa a m√∫sica atual.
    * **Pr√≥xima Faixa(Joinha üëç):** Pula para a pr√≥xima m√∫sica da playlist ou √°lbum.
    * **Faixa Anterior(M√£o aberta com os 5 dedos esticados üñê):** Volta para a m√∫sica anterior.
* **Interface Visual:** Exibe o feed da c√¢mera com caixas delimitadoras (bounding boxes) e r√≥tulos sobre os gestos detectados, fornecendo feedback visual instant√¢neo.
* **Integra√ß√£o Robusta:** Comunica-se diretamente com a API do Spotify, funcionando mesmo que o aplicativo n√£o esteja em foco.

## üõ†Ô∏è Tecnologias Utilizadas

A arquitetura do projeto foi constru√≠da utilizando um conjunto de ferramentas modernas para Deep Learning e desenvolvimento de aplica√ß√µes:

| Ferramenta          | Descri√ß√£o                                                                                             |
| :------------------ | :---------------------------------------------------------------------------------------------------- |
| **Python** | Linguagem principal para toda a l√≥gica do projeto.                                                    |
| **YOLOv8** | Modelo de Deep Learning de ponta para a detec√ß√£o de objetos (gestos) em tempo real.                   |
| **PyTorch** | Framework que serve como base para o treinamento e infer√™ncia do YOLOv8.                              |
| **OpenCV** | Biblioteca essencial para captura da webcam, manipula√ß√£o de imagens e exibi√ß√£o da interface visual.   |
| **Roboflow** | Plataforma utilizada para a anota√ß√£o e pr√©-processamento do dataset de imagens customizado.           |
| **Spotipy** | Wrapper Python para a API do Spotify, simplificando a autentica√ß√£o (OAuth 2.0) e os comandos.         |
| **Python-Dotenv** | Para gerenciamento seguro das credenciais da API, carregando-as a partir de um arquivo `.env`.        |
| **Google Colab** | Ambiente de nuvem utilizado para o treinamento do modelo com acelera√ß√£o por GPU.                      |

## ‚öôÔ∏è Configura√ß√£o e Instala√ß√£o

Siga os passos abaixo para executar o projeto localmente.

#### **Pr√©-requisitos**
* Python 3.9+
* Uma conta no Spotify (Premium √© recomendado para total funcionalidade da API)
* Uma webcam conectada

#### **Passos de Instala√ß√£o**

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/R1chardJr/YOLOV8-Gesture-Based-Media-Control.git
    cd YOLOV8-Gesture-Based-Media-Control
    ```

2.  **Crie e ative um ambiente virtual:**
    ```bash
    # Criar o ambiente
    python -m venv venv
    # Ativar no Windows
    .\venv\Scripts\activate
    # Ativar no macOS/Linux
    source venv/bin/activate
    ```


3.  **Configure a API do Spotify:**
    * V√° at√© o [Spotify for Developers Dashboard](https://developer.spotify.com/dashboard) e crie um novo App.
    * Copie seu **Client ID** e **Client Secret**.
    * Em "Edit Settings", adicione o seguinte **Redirect URI**: `http://127.0.0.1:8888/callback` e salve.

4.  **Configure as Vari√°veis de Ambiente:**
    * Na raiz do projeto, crie um arquivo chamado `.env`.
    * Abra o arquivo `.env` e preencha com suas credenciais do Spotify:
        ```env
        SPOTIPY_CLIENT_ID="SEU_CLIENT_ID_AQUI"
        SPOTIPY_CLIENT_SECRET="SEU_CLIENT_SECRET_AQUI"
        SPOTIPY_REDIRECT_URI="[http://127.0.0.1:8888/callback](http://127.0.0.1:8888/callback)"
        ```

## üöÄ Como Usar

1.  **Abra o Spotify:** Certifique-se de que o Spotify est√° aberto e tocando uma m√∫sica em algum dispositivo (computador, celular, etc.).
2.  **Execute o script principal:** Com seu ambiente virtual ativado, rode o comando:
    ```bash
    python hand_control_spotify.py
    ```
3.  **Autorize a Aplica√ß√£o:** Na primeira vez que rodar, uma janela do navegador abrir√° pedindo para voc√™ autorizar o acesso √† sua conta do Spotify. Fa√ßa o login e aprove.
4.  **Controle com Gestos:** Posicione sua m√£o em frente √† webcam e use os gestos treinados para controlar a m√∫sica.
5.  **Encerrar:** Pressione a tecla `Esc` para fechar a janela e encerrar o programa.

## üß† Treinamento do Modelo

O modelo `best.pt` inclu√≠do neste reposit√≥rio foi treinado em um dataset customizado. O processo foi o seguinte:
1.  **Coleta de Dados:** Centenas de imagens de 3 gestos (`next`, `play_pause`, `previous`) foram capturadas.
2.  **Anota√ß√£o:** As imagens foram anotadas na plataforma **Roboflow**, onde caixas delimitadoras foram desenhadas –¥–ª—è cada gesto.
3.  **Pr√©-processamento:** O dataset foi pr√©-processado com um *resize* para 640x640 pixels e *data augmentation* para aumentar a robustez do modelo.
4.  **Treinamento:** O modelo `yolov8n` foi treinado por 50 √©pocas no Google Colab, utilizando a t√©cnica de *fine-tuning*. O modelo final alcan√ßou uma m√©trica **mAP50 de 0.995**, indicando alt√≠ssima precis√£o na identifica√ß√£o dos gestos.

## üìÑ Documenta√ß√£o e Refer√™ncias

Para uma an√°lise mais aprofundada da metodologia, dos desafios encontrados e dos resultados detalhados deste projeto, consulte o artigo cient√≠fico elaborado como parte do trabalho:

* **[Artigo Completo: Desenvolvimento de um Sistema de Controle de M√≠dia por Gestos com YOLOv8 e API do Spotify](https://github.com/R1chardJr/YOLOV8-Gesture-Based-Media-Control/blob/main/Artigo_ProjetoFinal_Redes_Neurais_Richard.pdf)**

O artigo aborda em detalhes a fundamenta√ß√£o te√≥rica, a arquitetura do sistema, o processo de treinamento do modelo e a an√°lise dos resultados obtidos.

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

---
Feito com ‚ù§Ô∏è por **Richard Junior**.
